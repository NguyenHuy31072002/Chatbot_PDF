{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "[vnm-ocr-toolbox] Inference.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "ahMQhr-NCFwI",
        "QPa7rM_uCNNH",
        "GV1RTpooqFHA",
        "QsZQjgmPCioc",
        "6G7o-qUs9D5Q",
        "3VuS8JGyAcqx"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u9mrzttnCDoE",
        "outputId": "bda5e1a1-4014-4727-c133-4fe47be45f2a"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: line 1: nvidia-smi: command not found\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ahMQhr-NCFwI"
      },
      "source": [
        "# Clone repo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QRHqoJP8c-4z",
        "outputId": "1a141f98-79ad-4458-ae49-3e76e314ab68"
      },
      "source": [
        "!git clone https://github.com/kaylode/vnm-ocr-toolbox.git main\n",
        "%cd main"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'main'...\n",
            "remote: Enumerating objects: 1246, done.\u001b[K\n",
            "remote: Counting objects: 100% (80/80), done.\u001b[K\n",
            "remote: Compressing objects: 100% (43/43), done.\u001b[K\n",
            "remote: Total 1246 (delta 54), reused 58 (delta 37), pack-reused 1166 (from 1)\u001b[K\n",
            "Receiving objects: 100% (1246/1246), 23.63 MiB | 29.02 MiB/s, done.\n",
            "Resolving deltas: 100% (622/622), done.\n",
            "/content/main\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3k7a3m5jd4ha",
        "outputId": "42cb4ede-bbde-4a95-b76f-8560be27f909"
      },
      "source": [
        "%cd main\n",
        "!git checkout master\n",
        "!git reset --hard HEAD\n",
        "!git pull"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Errno 2] No such file or directory: 'main'\n",
            "/content/main\n",
            "Already on 'master'\n",
            "Your branch is up to date with 'origin/master'.\n",
            "HEAD is now at ef8744b update dataset link\n",
            "Already up to date.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QPa7rM_uCNNH"
      },
      "source": [
        "# Install dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c7-8JvToDpAP"
      },
      "source": [
        "%%capture\n",
        "%cd /content/main/\n",
        "!pip install -r requirements.txt"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GV1RTpooqFHA"
      },
      "source": [
        "# Download pretrained weights"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pylsd-nova # Install pylsd-nova instead of pylsd"
      ],
      "metadata": {
        "id": "tGqk9YWYb186",
        "outputId": "e04414fd-bfbf-4116-9e8a-a58a081e77f0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pylsd-nova\n",
            "  Downloading pylsd-nova-1.2.1.tar.gz (172 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/172.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m172.3/172.3 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: pylsd-nova\n",
            "  Building wheel for pylsd-nova (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pylsd-nova: filename=pylsd_nova-1.2.1-py3-none-any.whl size=172444 sha256=174790c5c683b8d81a384c70fe4d4af0d8dcdc24de6745e1f0999164f8b22947\n",
            "  Stored in directory: /root/.cache/pip/wheels/89/73/ea/c0aafa24ff079fe0ea8cf7382fd4e7c5aa5d22989046eb827a\n",
            "Successfully built pylsd-nova\n",
            "Installing collected packages: pylsd-nova\n",
            "Successfully installed pylsd-nova-1.2.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install shapely # Cài đặt shapely cho đối tượng Polygon"
      ],
      "metadata": {
        "id": "fJnNVpSSd9V9",
        "outputId": "df77d986-0f7f-4cc1-a952-8e32784f5740",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: shapely in /usr/local/lib/python3.10/dist-packages (2.0.6)\n",
            "Requirement already satisfied: numpy<3,>=1.14 in /usr/local/lib/python3.10/dist-packages (from shapely) (1.26.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyclipper"
      ],
      "metadata": {
        "id": "i9Mvo-6zeNHF",
        "outputId": "51958f2a-4f31-4610-e2ab-63ad85a589dc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyclipper\n",
            "  Using cached pyclipper-1.3.0.post6-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (9.0 kB)\n",
            "Downloading pyclipper-1.3.0.post6-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (912 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/912.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m912.2/912.2 kB\u001b[0m \u001b[31m33.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pyclipper\n",
            "Successfully installed pyclipper-1.3.0.post6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 546
        },
        "id": "0KIRpEe2qKcZ",
        "outputId": "30186d99-d438-46b2-8f4d-d66c618e15fd"
      },
      "source": [
        "# ipython-input-15-e8ebebf70510\n",
        "%cd /content/main\n",
        "# !mkdir \"/content/main/weights\"\n",
        "\n",
        "# Di chuyển lệnh import download_pretrained_weights đến đây\n",
        "from tool.utils import download_pretrained_weights\n",
        "\n",
        "# Bây giờ gọi download_pretrained_weights\n",
        "download_pretrained_weights(\"pan_resnet18_sroie19\", cached=\"/content/main/weights/PANNet_best_map.pth\")\n",
        "download_pretrained_weights(\"transformerocr_mcocr\", cached=\"/content/main/weights/transformerocr.pth\")\n",
        "download_pretrained_weights(\"phobert_mcocr\", cached=\"/content/main/weights/phobert_report.pth\")"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/main\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'torchvision.models.utils'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-91c2356bf91f>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Di chuyển lệnh import download_pretrained_weights đến đây\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdownload_pretrained_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# Bây giờ gọi download_pretrained_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/main/tool/utils.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdraw_bbox\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mdownload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mid_or_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcached\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmd5\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquiet\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mid_or_url\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'http'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/main/modules/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mpreprocess\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDocScanner\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetection\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mdetection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mocr\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mocr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mretrieval\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/main/modules/detection/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutil\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mshow_img\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdraw_bbox\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPAN\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_metric\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_dataloader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/main/modules/detection/predict.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mConfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutil\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0morder_points_clockwise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/main/modules/detection/models/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mPAN\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mYOLO\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_yolo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/main/modules/detection/models/PAN/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# @Time    : 2019/8/23 21:55\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# @Author  : zhoujun\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPANLoss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/main/modules/detection/models/PAN/model.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPAN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodules\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m backbone_dict = {'resnet18': {'models': resnet18, 'out': [64, 128, 256, 512]},\n",
            "\u001b[0;32m/content/main/modules/detection/models/PAN/modules/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# @Time    : 2019/8/23 21:54\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# @Author  : zhoujun\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mresnet\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mshufflenetv2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0msegmentation_head\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mFPEM_FFM\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mFPN\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/main/modules/detection/models/PAN/modules/resnet.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# @Author  : zhoujun\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mload_state_dict_from_url\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m __all__ = ['ResNet', 'resnet18', 'resnet34', 'resnet50', 'resnet101',\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torchvision.models.utils'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mK3olyTzC7Zj"
      },
      "source": [
        "# Inference"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QsZQjgmPCioc"
      },
      "source": [
        "## Inference script"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/main\n",
        "from IPython.display import Image\n",
        "from IPython.display import display\n",
        "\n",
        "\n",
        "\n",
        "!python run.py --input=/content/image.png --output=/content/main/results --do_retrieve --debug --find_best_rotation\n",
        "\n",
        "img1 = Image(f\"/content/main/data/mcocr/images/val/{IMAGE_ID}.jpg\", width=600)\n",
        "img2 = Image(f\"/content/main/results/{IMAGE_ID}/cache/preprocessed.jpg\", width=600)\n",
        "img3 = Image(f\"/content/main/results/{IMAGE_ID}/cache/detected.jpg\", width=600)\n",
        "img4 = Image(f\"/content/main/results/{IMAGE_ID}/result.jpg\", width=600)\n",
        "\n",
        "display(img1,img2,img3,img4)"
      ],
      "metadata": {
        "id": "J6VuzzfigPeq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Xphhqtuf0Za"
      },
      "source": [
        "%cd /content/main\n",
        "from IPython.display import Image\n",
        "from IPython.display import display\n",
        "\n",
        "IMAGE_ID = \"201be0a2fea60af853b7\"\n",
        "\n",
        "!python run.py --input=/content/\"{IMAGE_ID}\".jpg --output=/content/main/results/\"{IMAGE_ID}\" --do_retrieve --debug --find_best_rotation\n",
        "\n",
        "img1 = Image(f\"/content/main/data/mcocr/images/val/{IMAGE_ID}.jpg\", width=600)\n",
        "img2 = Image(f\"/content/main/results/{IMAGE_ID}/cache/preprocessed.jpg\", width=600)\n",
        "img3 = Image(f\"/content/main/results/{IMAGE_ID}/cache/detected.jpg\", width=600)\n",
        "img4 = Image(f\"/content/main/results/{IMAGE_ID}/result.jpg\", width=600)\n",
        "\n",
        "display(img1,img2,img3,img4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6G7o-qUs9D5Q"
      },
      "source": [
        "## Inference modules on Personal ID"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "687AkQvH9iy_"
      },
      "source": [
        "%cd /content/main\n",
        "import os\n",
        "import cv2\n",
        "import re\n",
        "import pandas as pd\n",
        "from modules import Preprocess, Detection, OCR, Correction\n",
        "from tool.utils import natural_keys, visualize\n",
        "import time\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "imEm3UjA9rAT"
      },
      "source": [
        "# Define some variables\n",
        "img_id = \"cmnd_Ngc_M_1_0012\"\n",
        "\n",
        "det_weight = None\n",
        "ocr_weight = None"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d1DYDYMlDI-C"
      },
      "source": [
        "# Read image\n",
        "img = cv2.imread(f\"/content/drive/MyDrive/AI Competitions/IDCard parser/aug/{img_id}.jpg\")\n",
        "\n",
        "plt.imshow(img)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H7PTOx4n-LEX"
      },
      "source": [
        "# Initialize modules\n",
        "\n",
        "det_model = Detection(weight_path=det_weight)\n",
        "ocr_model = OCR(weight_path=ocr_weight)\n",
        "preproc = Preprocess(\n",
        "    det_model=det_model,\n",
        "    ocr_model=ocr_model,\n",
        "    find_best_rotation=False)\n",
        "correction = Correction()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OfVejIJF-Vjd"
      },
      "source": [
        "# Preprocess image\n",
        "\n",
        "img1 = preproc(img)\n",
        "\n",
        "plt.imshow(img1)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TpF348x896FZ"
      },
      "source": [
        "# Detect texts\n",
        "\n",
        "boxes, img2  = det_model(\n",
        "    img1,\n",
        "    crop_region=True,                               #Crop detected regions for OCR\n",
        "    return_result=True,                             # Return plotted result\n",
        "    output_path=f\"/content/main/results/{img_id}\"   #Path to save cropped regions\n",
        ")\n",
        "\n",
        "plt.imshow(img2)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qm0rOndz-iVp"
      },
      "source": [
        "# Text OCR\n",
        "\n",
        "img_paths=os.listdir(f\"/content/main/results/{img_id}/crops\") # Cropped regions\n",
        "img_paths.sort(key=natural_keys)\n",
        "img_paths = [os.path.join(f\"/content/main/results/{img_id}/crops\", i) for i in img_paths]\n",
        "\n",
        "texts, probs = ocr_model.predict_folder(img_paths, return_probs=True) # OCR\n",
        "texts = correction(texts)   # Word correction\n",
        "\n",
        "for i in texts:\n",
        "    print(i)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Aqy4Yzc_CpK"
      },
      "source": [
        "preds, probs = None, None\n",
        "visualize(\n",
        "    img1, boxes, texts,\n",
        "    img_name = f'/content/main/results/{img_id}/result.jpg',\n",
        "    class_mapping=class_mapping,\n",
        "    labels = preds, probs = probs,\n",
        "    visualize_best=False)\n",
        "\n",
        "\n",
        "from IPython.display import Image\n",
        "from IPython.display import display\n",
        "\n",
        "img = Image(f\"/content/main/results/{img_id}/result.jpg\", width=600)\n",
        "display(img)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aH29PSfz_dJd"
      },
      "source": [
        "preds, probs = None, None\n",
        "visualize(\n",
        "    img1, boxes, texts,\n",
        "    img_name = f'/content/main/results/{img_id}/result.jpg',\n",
        "    class_mapping=class_mapping,\n",
        "    labels = preds, probs = probs,\n",
        "    visualize_best=False)\n",
        "\n",
        "end = time.time()\n",
        "print(f\"Executed in {end-start} s\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F_Neif1i-ytZ"
      },
      "source": [
        "!rm -rf \".cache\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3VuS8JGyAcqx"
      },
      "source": [
        "## Inference modules on Invoice"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FJTbAtgHAcqx"
      },
      "source": [
        "%cd /content/main\n",
        "import os\n",
        "import cv2\n",
        "import re\n",
        "import pandas as pd\n",
        "from modules import Preprocess, Detection, OCR, Retrieval, Correction\n",
        "from tool.utils import natural_keys, visualize\n",
        "import time\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NR4Xo7GCAcqz"
      },
      "source": [
        "# Define some auxiliary functions\n",
        "\n",
        "def find_highest_score_each_class(labels, probs):\n",
        "        best_score = [0] * (len(class_mapping.keys())-1)\n",
        "        best_idx = [-1] * (len(class_mapping.keys())-1)\n",
        "        for i, (label, prob) in enumerate(zip(labels, probs)):\n",
        "            label_idx = class_mapping[label]\n",
        "            if label_idx != class_mapping[\"NONE\"]:\n",
        "                if prob > best_score[label_idx]:\n",
        "                    best_score[label_idx] = prob\n",
        "                    best_idx[label_idx] = i\n",
        "        return best_idx\n",
        "\n",
        "def find_total_cost_value(total_cost_idx, boxes):\n",
        "    total_cost_box = boxes[total_cost_idx]\n",
        "    x1,y1 = total_cost_box[0]\n",
        "    for i in range(total_cost_idx+1, len(boxes)):\n",
        "        x1_,y1_ = boxes[i][0]\n",
        "\n",
        "        if abs(x1-x1_) < 2:\n",
        "          return i-1\n",
        "\n",
        "\n",
        "def extract_timestamp(text):\n",
        "    x = re.findall(r'\\d{2}:\\d{2}|\\d{2}:\\d{2}:\\d{2}|\\d{2}-\\d{2}-\\d{2}|\\d{2}\\.\\d{2}\\.\\d{2}|\\d+/\\d+/\\d+', text)\n",
        "    return ' '.join(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x5TUjYK3Acqz"
      },
      "source": [
        "# Define some variables\n",
        "img_id = \"mcocr_val_145115bxsnt\"\n",
        "class_mapping = {\"SELLER\":0, \"ADDRESS\":1, \"TIMESTAMP\":2, \"TOTAL_COST\":3, \"NONE\":4}\n",
        "idx_mapping = {0:\"SELLER\", 1:\"ADDRESS\", 2:\"TIMESTAMP\", 3:\"TOTAL_COST\", 4:\"NONE\"}\n",
        "\n",
        "det_weight = \"/content/drive/MyDrive/AI Competitions/MC-OCR/checkpoints/detection-checkpoints/best_rotation/PANNet_best_map.pth\"\n",
        "ocr_weight = \"/content/drive/MyDrive/AI Competitions/MC-OCR/checkpoints/ocr-checkpoints/transformerocr.pth\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HNmjeExwAcq0"
      },
      "source": [
        "# Read image\n",
        "img = cv2.imread(f\"/content/main/data/mcocr/images/val/{img_id}.jpg\")\n",
        "\n",
        "plt.imshow(img)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L5EGI4VhAcq0"
      },
      "source": [
        "# Initialize modules\n",
        "\n",
        "det_model = Detection(weight_path=det_weight)\n",
        "ocr_model = OCR(weight_path=ocr_weight)\n",
        "preproc = Preprocess(\n",
        "    det_model=det_model,\n",
        "    ocr_model=ocr_model,\n",
        "    find_best_rotation=False)\n",
        "retrieval = Retrieval(class_mapping, mode = 'all')\n",
        "correction = Correction()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "20Aw3tTgAcq1"
      },
      "source": [
        "# Preprocess image\n",
        "\n",
        "img1 = preproc(img)\n",
        "\n",
        "plt.imshow(img1)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N6PN_1_HAcq1"
      },
      "source": [
        "# Detect texts\n",
        "\n",
        "boxes, img2  = det_model(\n",
        "    img1,\n",
        "    crop_region=True,                               #Crop detected regions for OCR\n",
        "    return_result=True,                             # Return plotted result\n",
        "    output_path=f\"/content/main/results/{img_id}\"   #Path to save cropped regions\n",
        ")\n",
        "\n",
        "plt.imshow(img2)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v2ua1RP_Acq2"
      },
      "source": [
        "# Text OCR\n",
        "\n",
        "img_paths=os.listdir(f\"/content/main/results/{img_id}/crops\") # Cropped regions\n",
        "img_paths.sort(key=natural_keys)\n",
        "img_paths = [os.path.join(f\"/content/main/results/{img_id}/crops\", i) for i in img_paths]\n",
        "\n",
        "texts, probs = ocr_model.predict_folder(img_paths, return_probs=True) # OCR\n",
        "texts = correction(texts)   # Word correction\n",
        "\n",
        "for i in texts:\n",
        "    print(i)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jBHaqETRAcq2"
      },
      "source": [
        "preds, probs = retrieval(texts)\n",
        "\n",
        "# Custom post-process\n",
        "best_score_idx = find_highest_score_each_class(preds, probs)\n",
        "value_idx = find_total_cost_value(best_score_idx[3], boxes)\n",
        "if value_idx != best_score_idx[3]:\n",
        "    texts[best_score_idx[3]] += (\" \" + texts[value_idx])\n",
        "\n",
        "texts[best_score_idx[2]] = extract_timestamp(texts[best_score_idx[2]])\n",
        "\n",
        "# Visualize and save result\n",
        "visualize(\n",
        "    img1, boxes, texts,\n",
        "    img_name = f'/content/main/results/{img_id}/result.jpg',\n",
        "    class_mapping=class_mapping,\n",
        "    labels = preds, probs = probs,\n",
        "    visualize_best=True)\n",
        "\n",
        "with open(f\"/content/main/results/{img_id}/result.txt\", 'w') as f:\n",
        "    for cls, idx in enumerate(best_score_idx):\n",
        "        f.write(f\"{idx_mapping[cls]} : {texts[idx]}\\n\")\n",
        "\n",
        "from IPython.display import Image\n",
        "from IPython.display import display\n",
        "\n",
        "img = Image(f\"/content/main/results/{img_id}/result.jpg\", width=600)\n",
        "display(img)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}